# This runs a couple of tests on a gpu node.
# It helps diagnosis of health of perf issues.

type: command

code: src

command: /bin/bash ./gpu_perf_driver.sh

# to iterate quickly on your environment design, use inline
#environment: file:./environments/azureml/env.yml

# to reuse with different parameters, use registered environment 
# environment: azureml:nccltests_azureml:openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04
environment: azureml:nccltests_nvidia_pytorch:22.06-py3

# NOTE: set env var if needed by your configuration
environment_variables:
  NCCL_COLLNET_ENABLE: "1"
  NCCL_ALGO: "CollnetChain,NVLS"
  SHARP_COLL_ENABLE_SAT: "1"
  SHARP_COLL_LOG_LEVEL: "3 
  SHARP_COLL_ENABLE_PCI_RELAXED_ORDERING: "1"
  UCX_TLS: "rc"
  UCX_NET_DEVICES: "mlx5_ib0:1"
  CUDA_DEVICE_ORDER: "PCI_BUS_ID" 
  NCCL_SOCKET_IFNAME: "eth0"
  NCCL_DEBUG: "warn"
  NCCL_NET_GDR_LEVEL: "5"
  NCCL_MIN_NCHANNELS: "32"
  NCCL_TOPO_FILE: "/opt/microsoft/ndv5-topo.xml"


compute: azureml:four-nodes

distribution:
  type: mpi
  process_count_per_instance: 1 # NOTE: set equal to number of gpus on the node

resources:
  instance_count: 4 # NOTE: to use multiple nodes

services:
  my_vs_code:
    type: vs_code
    nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are "all", or compute node index (for ex. "0", "1" etc.)
  my_jupyter_lab:
    type: jupyter_lab
    nodes: all

experiment_name: nccl-test
display_name: Gpu Diag (NCCL tests)
description: Runs NCCL-tests on gpu nodes.
